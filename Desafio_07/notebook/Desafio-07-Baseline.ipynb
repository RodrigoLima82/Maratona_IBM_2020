{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cloudant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imblearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import de bibliotecas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from cloudant import Cloudant\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import dos módulos\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Imports para formatação dos gráficos\n",
    "import matplotlib as m\n",
    "plt.style.use('fivethirtyeight')\n",
    "m.rcParams['axes.labelsize'] = 14\n",
    "m.rcParams['xtick.labelsize'] = 12\n",
    "m.rcParams['ytick.labelsize'] = 12\n",
    "m.rcParams['text.color'] = 'k'\n",
    "from matplotlib.pylab import rcParams \n",
    "rcParams['figure.figsize'] = 14,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicao das variaveis de conexao\n",
    "\n",
    "user     = \"ad7fd206-cbed-4b75-aa98-a9fd2e05c755-bluemix\"\n",
    "password = \"a2537397c518fcd38947f38ce8c72c17903732bb61f838c05e5b56a29c9de0aa\"\n",
    "account  = \"ad7fd206-cbed-4b75-aa98-a9fd2e05c755-bluemix\" \n",
    "db_name  = \"desafio7-iot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para carregar os dados do banco de dados NoSQL Cloudant\n",
    "def obter_dados(user, password, account, db_name):\n",
    "\n",
    "    client = Cloudant(user, password, account=account, connect=True, auto_renew=True)\n",
    "\n",
    "    db = client[db_name]\n",
    "\n",
    "    response = db.all_docs(limit=20000, include_docs=True)\n",
    "\n",
    "    docs = []\n",
    "    for r in response[\"rows\"]:\n",
    "        docs.append(r['doc'])\n",
    "\n",
    "    return docs\n",
    "\n",
    "# Verificando se existem registros duplicados no dataset\n",
    "def verify_dup_rows(data):\n",
    "    \n",
    "    # Obtendo somente linhas duplicadas\n",
    "    tmp = data[data.duplicated()]\n",
    "\n",
    "    print(\"Linhas duplicadas até o momento:\")\n",
    "    print(tmp.shape)\n",
    "    \n",
    "    del tmp\n",
    "    \n",
    "    \n",
    "# Funcao para verificar valores missing no dataset\n",
    "def check_missing(df, display = 10):\n",
    "    temp_df = df.copy()\n",
    "    df_nan = (temp_df.isnull().sum() / len(temp_df)) * 100\n",
    "    missing_data = pd.DataFrame({'Missing n': temp_df.isnull().sum(),'% Missing' :df_nan})\n",
    "    if missing_data['Missing n'].sum() == 0:\n",
    "        return print('Ótimo! Não há mais valores faltantes neste dataset.')\n",
    "    else:\n",
    "        return missing_data.sort_values('% Missing', ascending = False).head(display)\n",
    "\n",
    "# Funcao para preencher os dados missing de algumas colunas\n",
    "def preenche_missing(df):\n",
    "    \n",
    "    df.dropna(axis='index', how='any', subset=['Tempo', 'Estação', 'LAT', 'LONG', \n",
    "                                               'Movimentação', 'Original_473', \n",
    "                                               'Original_269', 'Zero', 'Maçã-Verde', \n",
    "                                               'Tangerina', 'Citrus', 'Açaí-Guaraná', \n",
    "                                               'Pêssego'])\n",
    "\n",
    "    # coloca constante 0 em outras colunas com dados missing\n",
    "    impute_zeros = SimpleImputer(\n",
    "                                    missing_values=np.nan,\n",
    "                                    strategy='constant',\n",
    "                                    fill_value=0,\n",
    "                                    verbose=0,\n",
    "                                    copy=True\n",
    "                                )\n",
    "    \n",
    "    impute_zeros.fit(X=df)\n",
    "\n",
    "    # Reconstruindo um Pandas DataFrame com os resultados\n",
    "    data = pd.DataFrame.from_records(\n",
    "            data = impute_zeros.transform(\n",
    "            X    = df\n",
    "        ),\n",
    "        columns=df.columns\n",
    "    )    \n",
    "    \n",
    "    # Converte colunas para numerico\n",
    "    data = data.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    return data\n",
    "\n",
    "# Funcao para trabalhar as features\n",
    "def fe(df):\n",
    "\n",
    "    # Removendo colunas unicas\n",
    "    data = df.drop(['Tempo', 'Estação', 'LAT', 'LONG', 'Movimentação', '_id', '_rev', 'row'], axis = 1)\n",
    "\n",
    "    # Removendo registros duplicados\n",
    "    data = data.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Funcao para transformar features categoricas em numericas\n",
    "def fe_cat_num(df):\n",
    "\n",
    "    # Tratando variáveis categóricas com o método Pandas ``get_dummies()''\n",
    "    df = pd.get_dummies(df, columns=['xxxx'])\n",
    "\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dataframe a partir da lista de dados vindo do IoT e gravados no NoSQL\n",
    "train = pd.DataFrame(data=obter_dados(user, password, account, db_name))\n",
    "\n",
    "# Carregando o dataset de testes \n",
    "test  = pd.read_csv(r'teste_desafio_7.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ótimo! Não há mais valores faltantes neste dataset.\n",
      "(3482, 9)\n",
      "\n",
      "\n",
      "Linhas duplicadas até o momento:\n",
      "(0, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_473</th>\n",
       "      <th>Original_269</th>\n",
       "      <th>Zero</th>\n",
       "      <th>Maçã-Verde</th>\n",
       "      <th>Tangerina</th>\n",
       "      <th>Citrus</th>\n",
       "      <th>Açaí-Guaraná</th>\n",
       "      <th>Pêssego</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>18</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>36</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>65</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>REABASTECER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>65</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>43</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>86</td>\n",
       "      <td>49</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>52</td>\n",
       "      <td>59</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>REABASTECER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>76</td>\n",
       "      <td>65</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>86</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>REABASTECER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Original_473  Original_269  Zero  Maçã-Verde  Tangerina  Citrus  \\\n",
       "0            45            18    59          14         32      19   \n",
       "1            65            31    65          23         20      37   \n",
       "2            62            55    36          43         35      25   \n",
       "3            11            43    65          39         43      33   \n",
       "4            59            65    40          20         39       9   \n",
       "5            63            65    65          31         19      20   \n",
       "6            86            49    34          14         17      43   \n",
       "7            17            52    59          40          7      28   \n",
       "8            76            65    44          24         15      39   \n",
       "9            86            27    24           2         37       3   \n",
       "\n",
       "   Açaí-Guaraná  Pêssego       TARGET  \n",
       "0            13       21       NORMAL  \n",
       "1            15       15       NORMAL  \n",
       "2            24       26       NORMAL  \n",
       "3             3       35  REABASTECER  \n",
       "4            43       34       NORMAL  \n",
       "5            13       43       NORMAL  \n",
       "6            22       35       NORMAL  \n",
       "7             3       29  REABASTECER  \n",
       "8            13       21       NORMAL  \n",
       "9            36        8  REABASTECER  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "treino = preenche_missing(train)    \n",
    "treino = fe(treino)   \n",
    "\n",
    "# Removendo outliers\n",
    "#treino = treino[treino['modulos_finalizados'] <= 500]\n",
    "\n",
    "# Verificando as colunas com dados missing do dataset\n",
    "check_missing(treino, display = 15)\n",
    "\n",
    "print(treino.shape)\n",
    "\n",
    "print('\\n')\n",
    "# Verificar os registros duplicados\n",
    "verify_dup_rows(treino)\n",
    "\n",
    "treino.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3482 entries, 0 to 3481\n",
      "Data columns (total 9 columns):\n",
      "Original_473    3482 non-null int64\n",
      "Original_269    3482 non-null int64\n",
      "Zero            3482 non-null int64\n",
      "Maçã-Verde      3482 non-null int64\n",
      "Tangerina       3482 non-null int64\n",
      "Citrus          3482 non-null int64\n",
      "Açaí-Guaraná    3482 non-null int64\n",
      "Pêssego         3482 non-null int64\n",
      "TARGET          3482 non-null object\n",
      "dtypes: int64(8), object(1)\n",
      "memory usage: 245.0+ KB\n"
     ]
    }
   ],
   "source": [
    "treino.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando features para treinamento\n",
    "X = treino[['Original_473', 'Original_269', 'Zero', 'Maçã-Verde', 'Tangerina', 'Citrus', 'Açaí-Guaraná', 'Pêssego']]\n",
    "\n",
    "# Selecionando feature target\n",
    "y = treino['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NORMAL       0.78      0.84      0.81       470\n",
      " REABASTECER       0.61      0.51      0.55       227\n",
      "\n",
      "    accuracy                           0.73       697\n",
      "   macro avg       0.70      0.68      0.68       697\n",
      "weighted avg       0.73      0.73      0.73       697\n",
      "\n",
      "F1_macro   :  0.6826242662170644\n",
      "F1_micro   :  0.7345767575322812\n",
      "F1_weighted:  0.7273918385206022\n",
      "F1_none    :  [0.81103166 0.55421687]\n"
     ]
    }
   ],
   "source": [
    "# Split dos dados em treino e validacao\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=133)\n",
    "\n",
    "# Treinamento com GradientBoosting\n",
    "model_gbc = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Validacao do modelo\n",
    "y_pred_val = model_gbc.predict(X_valid)\n",
    "\n",
    "# Salvando o score\n",
    "gbc_score = f1_score(y_valid, y_pred_val, average='weighted')\n",
    "\n",
    "# Matriz de Classificacao\n",
    "print(classification_report(y_valid, y_pred_val))\n",
    "\n",
    "# Avaliacao da metrica F1\n",
    "print('F1_macro   : ', f1_score(y_valid, y_pred_val, average='macro'))\n",
    "print('F1_micro   : ', f1_score(y_valid, y_pred_val, average='micro'))\n",
    "print('F1_weighted: ', f1_score(y_valid, y_pred_val, average='weighted'))\n",
    "print('F1_none    : ', f1_score(y_valid, y_pred_val, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NORMAL       0.69      0.94      0.80       470\n",
      " REABASTECER       0.51      0.12      0.19       227\n",
      "\n",
      "    accuracy                           0.68       697\n",
      "   macro avg       0.60      0.53      0.49       697\n",
      "weighted avg       0.63      0.68      0.60       697\n",
      "\n",
      "F1_macro   :  0.4949923057194152\n",
      "F1_micro   :  0.6757532281205165\n",
      "F1_weighted:  0.6003278072625029\n",
      "F1_none    :  [0.79712747 0.19285714]\n"
     ]
    }
   ],
   "source": [
    "# Split dos dados em treino e validacao\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=133)\n",
    "\n",
    "# Treinamento com GradientBoosting\n",
    "model_lr = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# Validacao do modelo\n",
    "y_pred_val = model_lr.predict(X_valid)\n",
    "\n",
    "# Salvando o score\n",
    "lr_score = f1_score(y_valid, y_pred_val, average='weighted')\n",
    "\n",
    "# Matriz de Classificacao\n",
    "print(classification_report(y_valid, y_pred_val))\n",
    "\n",
    "# Avaliacao da metrica F1\n",
    "print('F1_macro   : ', f1_score(y_valid, y_pred_val, average='macro'))\n",
    "print('F1_micro   : ', f1_score(y_valid, y_pred_val, average='micro'))\n",
    "print('F1_weighted: ', f1_score(y_valid, y_pred_val, average='weighted'))\n",
    "print('F1_none    : ', f1_score(y_valid, y_pred_val, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NORMAL       0.72      0.90      0.80       470\n",
      " REABASTECER       0.57      0.26      0.36       227\n",
      "\n",
      "    accuracy                           0.70       697\n",
      "   macro avg       0.64      0.58      0.58       697\n",
      "weighted avg       0.67      0.70      0.66       697\n",
      "\n",
      "F1_macro   :  0.5809112154834025\n",
      "F1_micro   :  0.6958393113342898\n",
      "F1_weighted:  0.6574249888855002\n",
      "F1_none    :  [0.80037665 0.36144578]\n"
     ]
    }
   ],
   "source": [
    "# Split dos dados em treino e validacao\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=133)\n",
    "\n",
    "# Treinamento com GradientBoosting\n",
    "model_knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Validacao do modelo\n",
    "y_pred_val = model_knn.predict(X_valid)\n",
    "\n",
    "# Salvando o score\n",
    "knn_score = f1_score(y_valid, y_pred_val, average='weighted')\n",
    "\n",
    "# Matriz de Classificacao\n",
    "print(classification_report(y_valid, y_pred_val))\n",
    "\n",
    "# Avaliacao da metrica F1\n",
    "print('F1_macro   : ', f1_score(y_valid, y_pred_val, average='macro'))\n",
    "print('F1_micro   : ', f1_score(y_valid, y_pred_val, average='micro'))\n",
    "print('F1_weighted: ', f1_score(y_valid, y_pred_val, average='weighted'))\n",
    "print('F1_none    : ', f1_score(y_valid, y_pred_val, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NORMAL       0.80      0.83      0.81       470\n",
      " REABASTECER       0.61      0.57      0.59       227\n",
      "\n",
      "    accuracy                           0.74       697\n",
      "   macro avg       0.71      0.70      0.70       697\n",
      "weighted avg       0.74      0.74      0.74       697\n",
      "\n",
      "F1_macro   :  0.702410285155458\n",
      "F1_micro   :  0.7431850789096126\n",
      "F1_weighted:  0.7408144513657664\n",
      "F1_none    :  [0.81256545 0.59225513]\n"
     ]
    }
   ],
   "source": [
    "# Split dos dados em treino e validacao\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=133)\n",
    "\n",
    "# Treinamento com GradientBoosting\n",
    "model_dtc = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Validacao do modelo\n",
    "y_pred_val = model_dtc.predict(X_valid)\n",
    "\n",
    "# Salvando o score\n",
    "dtc_score = f1_score(y_valid, y_pred_val, average='weighted')\n",
    "\n",
    "# Matriz de Classificacao\n",
    "print(classification_report(y_valid, y_pred_val))\n",
    "\n",
    "# Avaliacao da metrica F1\n",
    "print('F1_macro   : ', f1_score(y_valid, y_pred_val, average='macro'))\n",
    "print('F1_micro   : ', f1_score(y_valid, y_pred_val, average='micro'))\n",
    "print('F1_weighted: ', f1_score(y_valid, y_pred_val, average='weighted'))\n",
    "print('F1_none    : ', f1_score(y_valid, y_pred_val, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NORMAL       0.87      0.79      0.83       470\n",
      " REABASTECER       0.64      0.76      0.69       227\n",
      "\n",
      "    accuracy                           0.78       697\n",
      "   macro avg       0.76      0.78      0.76       697\n",
      "weighted avg       0.80      0.78      0.79       697\n",
      "\n",
      "F1_macro   :  0.7625681296615032\n",
      "F1_micro   :  0.7819225251076041\n",
      "F1_weighted:  0.7862018889248324\n",
      "F1_none    :  [0.83035714 0.69477912]\n"
     ]
    }
   ],
   "source": [
    "# Split dos dados em treino e validacao\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=133)\n",
    "\n",
    "# Treinamento com GradientBoosting\n",
    "model_rfc = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Validacao do modelo\n",
    "y_pred_val = model_rfc.predict(X_valid)\n",
    "\n",
    "# Salvando o score\n",
    "rfc_score = f1_score(y_valid, y_pred_val, average='weighted')\n",
    "\n",
    "# Matriz de Classificacao\n",
    "print(classification_report(y_valid, y_pred_val))\n",
    "\n",
    "# Avaliacao da metrica F1\n",
    "print('F1_macro   : ', f1_score(y_valid, y_pred_val, average='macro'))\n",
    "print('F1_micro   : ', f1_score(y_valid, y_pred_val, average='micro'))\n",
    "print('F1_weighted: ', f1_score(y_valid, y_pred_val, average='weighted'))\n",
    "print('F1_none    : ', f1_score(y_valid, y_pred_val, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NORMAL       0.83      0.81      0.82       470\n",
      " REABASTECER       0.62      0.66      0.64       227\n",
      "\n",
      "    accuracy                           0.76       697\n",
      "   macro avg       0.73      0.73      0.73       697\n",
      "weighted avg       0.76      0.76      0.76       697\n",
      "\n",
      "F1_macro   :  0.7279035547886508\n",
      "F1_micro   :  0.757532281205165\n",
      "F1_weighted:  0.7592069483504463\n",
      "F1_none    :  [0.81769148 0.63811563]\n"
     ]
    }
   ],
   "source": [
    "# Split dos dados em treino e validacao\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=133)\n",
    "\n",
    "# Treinamento com GradientBoosting\n",
    "model_xgb = XGBClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Validacao do modelo\n",
    "y_pred_val = model_xgb.predict(X_valid)\n",
    "\n",
    "# Salvando o score\n",
    "xgb_score = f1_score(y_valid, y_pred_val, average='weighted')\n",
    "\n",
    "# Matriz de Classificacao\n",
    "print(classification_report(y_valid, y_pred_val))\n",
    "\n",
    "# Avaliacao da metrica F1\n",
    "print('F1_macro   : ', f1_score(y_valid, y_pred_val, average='macro'))\n",
    "print('F1_micro   : ', f1_score(y_valid, y_pred_val, average='micro'))\n",
    "print('F1_weighted: ', f1_score(y_valid, y_pred_val, average='weighted'))\n",
    "print('F1_none    : ', f1_score(y_valid, y_pred_val, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBC</th>\n",
       "      <td>0.727392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.600328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.657425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC</th>\n",
       "      <td>0.740814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>0.786202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>0.759207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy\n",
       "GBC  0.727392\n",
       "LR   0.600328\n",
       "KNN  0.657425\n",
       "DTC  0.740814\n",
       "RFC  0.786202\n",
       "XGB  0.759207"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepara a lista de resultados\n",
    "metricas = [(gbc_score),(lr_score),(knn_score),(dtc_score),(rfc_score),(xgb_score)]\n",
    "\n",
    "# Cria o dataframe\n",
    "df_metricas = pd.DataFrame(metricas, \n",
    "                           columns = ['Accuracy'], \n",
    "                           index = ['GBC', 'LR', 'KNN', 'DTC', 'RFC', 'XGB']) \n",
    "\n",
    "# Visualiza o resultado\n",
    "df_metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
